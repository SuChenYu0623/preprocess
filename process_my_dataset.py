import concurrent.futures
import requests
from pymongo import MongoClient
import hashlib
import csv
from io import BytesIO
import requests
from PIL import Image
import time

setting = {
    "saveDataPath":
    "/home/chris/Desktop/crawlSystem/preprocess/newsDataset2",
    "saveImagePath":
    "/home/chris/Desktop/crawlSystem/preprocess/newsDataset2/images"
}


def is_valid_image_url(imageId, url, setting=setting):
    try:
        headers = {
            "User-Agent": "Mozilla/5.0"  # æ¨¡æ“¬æ­£å¸¸ç€è¦½å™¨è«‹æ±‚
        }
        response = requests.get(url, headers=headers, timeout=10)
        if response.status_code == 200 and 'image' in response.headers.get(
                'Content-Type', ''):
            try:
                # é©—è­‰åœ–ç‰‡æ˜¯å¦æœ‰æ•ˆ
                img = Image.open(BytesIO(response.content))
                img.verify()

                # é‡æ–°æ‰“é–‹ï¼Œverifyæœƒç ´å£æª”æ¡ˆæŒ‡æ¨™
                img = Image.open(BytesIO(response.content))
                file_extension = img.format.lower()
                img.save(
                    f"{setting['saveImagePath']}/{imageId}.{file_extension}")
                # print("âœ… åœ–ç‰‡ä¸‹è¼‰æˆåŠŸä¸”å…§å®¹æœ‰æ•ˆ")
                # return True
                return f'{imageId}.{file_extension}'
            except Exception as e:
                print(f"âš ï¸ åœ–ç‰‡å…§å®¹æå£æˆ–ä¸æ˜¯åœ–ç‰‡ï¼š{e},  url: {url}")
                return False
        else:
            print(
                f"âŒ ç„¡æ•ˆçš„åœ–ç‰‡é€£çµæˆ– Content-Type éŒ¯èª¤: {response.status_code}, {response.headers.get('Content-Type')}, url: {url}"
            )
            return False
    except requests.RequestException as e:
        print(f"ğŸš« ç¶²è·¯éŒ¯èª¤ï¼š{e}, url: {url}")
        return False


def encrypt_src_md5(src, length=8):
    # å°‡ src ç·¨ç¢¼å¾Œé€²è¡Œ MD5 é›œæ¹Š
    hash_obj = hashlib.md5(src.encode('utf-8'))
    # å–å¾— 32 å­—å…ƒçš„ hex digestï¼Œå†å–å‰ length å€‹å­—å…ƒ
    code = hash_obj.hexdigest()[:length]
    return code


def parseImageInfo(imageId, caption, src, newsId):
    if not imageId: return
    if not caption: return
    if not src: return
    if not newsId: return
    return {
        "image": imageId,
        "caption": caption,
        "src": src,
        "newsId": newsId,
        "download": False
    }


def parseDocToImageInfo(doc):
    result = []
    newsId = doc["newsId"]
    summary = doc.get("summary", None)
    images_with_desc = doc["images_with_desc"]

    # å¾ images_with_desc æ‹¿
    for image_with_desc in images_with_desc:
        src = image_with_desc.get("src", None)
        alt = image_with_desc.get("alt", None)
        desc = image_with_desc.get("desc", None) or image_with_desc.get(
            "caption", None)

        encrypt_src = encrypt_src_md5(src)
        imageId = f'{newsId}_{encrypt_src}'

        image_name = is_valid_image_url(imageId=imageId, url=src)
        if src and image_name:
            if alt:
                imageInfo = parseImageInfo(image_name, alt, src, newsId)
                result.append(imageInfo)

            if desc:
                imageInfo = parseImageInfo(image_name, desc, src, newsId)
                result.append(imageInfo)

    # summary
    if summary and len(summary.split(' ')) < 50:
        imageInfo = parseImageInfo(imageId, summary, src, newsId)
        result.append(imageInfo)

    return result


client = MongoClient("mongodb://localhost:27017/")
db = client["crawl_database"]
collection = db["crawl_items"]
print('collection', collection)
query = {"downloaded": False}  # ç¯©é¸æœªçˆ¬å–çš„è³‡æ–™
querySource = {"_id": 0, "newsId": 1, "images_with_desc": 1, "summary": 1}
size = 11000
cursor = collection.find(query, querySource,
                         no_cursor_timeout=True).sort("postTime",
                                                      1).limit(size)

docs = [doc for doc in cursor]
print(len(docs))

# imageInfoList = []
# # for idx, doc in enumerate(cursor):
# for idx, doc in enumerate(docs):
#     try:
#         if idx % 100 == 0:
#             print(f"idx: {idx}, total: {size}")
#         result = parseDocToImageInfo(doc)
#         imageInfoList += result  # åˆä½µ
#         time.sleep(5)
#     except Exception as e:
#         print(f'{idx}, {e}')

# print(len(imageInfoList))
# print(type(imageInfoList))

# # å¯«å…¥ csv
# fields = imageInfoList[0].keys()
# with open(f'{setting["saveDataPath"]}/captions.csv', 'w',
#           newline='') as csvfile:
#     writer = csv.DictWriter(csvfile, fieldnames=fields)
#     writer.writeheader()  # å¯«å…¥æ¨™é¡Œï¼ˆæ¬„ä½åç¨±ï¼‰
#     writer.writerows(imageInfoList)  # ä½¿ç”¨ writerows() ä¸€æ¬¡æ€§å°‡æ‰€æœ‰è³‡æ–™å¯«å…¥

# print(f'CSV æª”æ¡ˆ list.csv å·²æˆåŠŸå»ºç«‹ã€‚')
